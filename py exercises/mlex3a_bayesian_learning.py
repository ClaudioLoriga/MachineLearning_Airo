# -*- coding: utf-8 -*-
"""MLEx3a.Bayesian_Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AqVaqOJPp0v2vqjJuXewPm2elLGJ0Wvw

# Machine Learning Exercise
# 3a. Bayesian Learning

See description of the example in Russel & Norvig: Artificial Intelligence: A modern approach. Chap. 20.
"""

import numpy as np

"""## Prior knowledge"""

PH = np.array([0.1, 0.2, 0.4, 0.2, 0.1]) # we have 5 kinds of bags of candies

PdH = {}
PdH['l'] = np.array([0.0, 0.25, 0.5, 0.75, 1.0]) # 'l' -> lime
PdH['c'] = 1 - PdH['l'] # 'c' -> cherry

print('P(H) = %s' %(str(PH)))
print('P(l|H) = %s' %(str(PdH['l']))) # likelihood for lime candy
print('P(c|H) = %s' %(str(PdH['c']))) # likelihood for cherry candy

# Probability of extracting a lime candy
cP = PdH['l'] * PH
Pl = np.sum(cP)
print('P(l) = sum %s = %.3f' %(str(cP),Pl))

"""## Dataset"""

D = ['l','l','l','l','l']

"""## Bayesian Learning"""

np.set_printoptions(formatter={'float': '{: 0.3f}'.format})
P = PH
db = ''
print('P(H)      \t= %s' %(str(PH)))
for d in D:
    P = P * PdH[d]
    # Why is P divided by sum(p)?:
    # Remember the normalizing constant alpha that is used to reduce any probability function
    # to a density function with a total probability of 1.
    P = P / np.sum(P)
    db = db+d
    print('P(H|%s)  \t= %s' %(db,str(P)))

"""## MAP hypothesis"""

i = np.argmax(P)
print('MAP hypothesis: h%d' %(i+1))

"""## Prediction

Probability that next candy is lime

Using MAP hypothesis
"""

PlhMAP = PdH['l'][i]
print('P(l|h_MAP) = %.3f' %(PlhMAP))

"""Using all hypotheses"""

cP = PdH['l'] * P
PlD = np.sum(cP)
print('P(l|D) = sum %s = %.3f' %(str(cP),PlD))

"""# Home Exercise

Consider the following random variables:

Di : outcome of rolling a 6-faces die

Z = D1 + D2 = sum of the outcomes of rolling 2 dice

S = D1 + D2 + D3 = sum of the outcomes of rolling 3 dice

Z in [2,12], S in [3,18]

**Question 1**

Write Python code to estimate the following probabilities:

Prior: P(S)  -- 16 values summing to 1

Posterior: P( S | D1 ) -- 16 x 6 matrix (each column sums to 1)

Posterior: P( S | D1, D2 ) -- 16 x 6 x 6 matrix (each column sums to 1)

Posterior: P( S | Z ) -- 16 x 11 matrix (each column sums to 1)

----

Compare the above experimental results with analytical values.

**Question 2**

Verify experimentally that

P( S | Z, D1 ) = P ( S | Z )


"""